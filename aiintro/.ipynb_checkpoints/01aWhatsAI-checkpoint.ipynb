{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Rational Agents\n",
    "* Author: Johannes Maucher\n",
    "* Last Update: 15.10.2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Goals of this section:**\n",
    "* Raise awareness of the essential factors of (artificial) intelligence\n",
    "* Understand AI definition of [S. Russel and P. Norvig](http://aima.cs.berkeley.edu)\n",
    "* This definition yields a <font color=\"red\">process model</font> for a structured development of any AI-project $\\Rightarrow$ <font color=\"red\">Learn to proceed according to this model.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Intelligence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "font_size": "36px",
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Artificial Intelligence?\n",
    "\n",
    "AI develops ...\n",
    "\n",
    "<img src=\"https://maucher.home.hdm-stuttgart.de/Pics/aiDefinitions.png\" style=\"width:400px\">\n",
    "\n",
    "Engineer's definition ([S. Russel and P. Norvig](http://aima.cs.berkeley.edu)): <font color = red>*AI develops rational agents*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Rational Agents\n",
    "\n",
    "![agentGeneral.png](https://maucher.home.hdm-stuttgart.de/Pics/agentGeneral.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "A rational agent is anything that is\n",
    "1. **perceiving** its environment through sensors\n",
    "2. **thinking** and deciding on the next actions\n",
    "2. **acting** through actuators\n",
    "\n",
    "Rational means, that the agent acts in a way that is expected to maximize its performance measure, given it's\n",
    "* built-in knowledge\n",
    "* perceived experience\n",
    "* acting capabilities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Specification of Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. AI-specific specification of problem domain\n",
    "2. Determines which <font color=\"red\">agent type</font> is required\n",
    "3. Agent type determines \n",
    "    - required modules in the agent\n",
    "    - algorithm categories required in the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Environment consists of\n",
    "* **P**erformance Measure\n",
    "* **E**nvironment\n",
    "* **A**ctors\n",
    "* **S**ensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Environment Attributes\n",
    "* fully or partially **observable**\n",
    "* **Deterministic** or **Stochastic**\n",
    "* **Episodic** or **Sequential**\n",
    "* **Static**, **Semi-Static** or **Dynamic**\n",
    "* **Single-** or **Multi-Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agent Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simple-Reflex Agent \n",
    "\n",
    "![agentGeneral.png](https://maucher.home.hdm-stuttgart.de/Pics/agentRule.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The **Simple-Reflex-Agent** seems quite unintelligent. It applies it's set of rules on the current perceived state in order to select an action. Note that this type of agent even does not have a memory. Example:\n",
    "* theromstat\n",
    "* simple web-site, which reacts on klicks and provides new views, pages, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model-based Agent\n",
    "![agentModel.png](https://maucher.home.hdm-stuttgart.de/Pics/agentModel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the environment is not fully-observable, the non-observable part must be modelled. The model may describe how\n",
    "- the environment behaves independent of the agent (external state)\n",
    "- how the agent behaves in the environment (internal state)\n",
    "\n",
    "Examples:\n",
    "- In recommender systems users are modelled by their previous purchases\n",
    "- In autonomous driving movement of other vehicles, pedestrians, ... is modelled\n",
    "- Search engines model the user by their click-history, location, ... \n",
    "- Cleaning robots may learn a dirt-distribution model of rooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Goal-based Agent\n",
    "![agentGoal.png](https://maucher.home.hdm-stuttgart.de/Pics/agentGoal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In Goal-based agents one or a set of goals are given. The task is typically to find/plan a sequence of actions, which efficiently lead from the current state to a goal-state. Note that the planning of actions is done offline. Only after a path to the goal has been found, the corresponding actions are executed. \n",
    "\n",
    "Examples:\n",
    "* Pathfinding, Navigation\n",
    "* Planning in board-games such as checkers, chess, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Utility-based Agent\n",
    "![agentUtility.png](https://maucher.home.hdm-stuttgart.de/Pics/agentUtility.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Utility-based agents are similar to goal-based agents. They are applicable if \n",
    "* concrete goals can hardly be defined, \n",
    "* if many goals exist,\n",
    "* if a complete planning from the current state to a goal state may be too complex,\n",
    "\n",
    "Utility based agents can bea applied for all **kinds of optimization problems**. Prerequisite is the definition of a utility-function.\n",
    "\n",
    "Examples:\n",
    "* In board-games like chess planning to the end is way to complex. Instead planning is done only for a predefined number of next moves (planning horizon). Then a utility-function is required to evaluate all states, which are reachable within the planning horizon.\n",
    "* Logistic\n",
    "* Scheduling\n",
    "* Network coverage \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Knowledge-based Agent\n",
    "![agentKnowledge.png](https://maucher.home.hdm-stuttgart.de/Pics/agentKnowledge.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Knowledge-based agents infere their actions, based on a comprehensive knowledge-base. There may exist some in-built-knowledge, but knowledge increases while the agent acts in it's environments and perceives new experience. Key-elements of this type of agents are:\n",
    "* Formal knowledge representation, e.g. by knowledge graphs, first-order-logic, probabilities, \n",
    "* Ways to infere new knowledge and actions (logic solvers, Bayes-Net, etc.)\n",
    "\n",
    "Example:\n",
    "* Expert-Systems for e.g. medical or technical diagnosis\n",
    "* IBM-Watson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learning Agent\n",
    "![agentLearning.png](https://maucher.home.hdm-stuttgart.de/Pics/agentLearn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "* **Performing element** is any of the agent types, described above. E.g. if it is \n",
    "    - a simple-reflex agent, the rules can be learned\n",
    "    - a model-based agent, the model can be learned\n",
    "    - a goal-based agent, the goals can be adapted\n",
    "    - ...\n",
    "* The **Compare**-block evaluates the current perceived state with respect to the performance measure and provides negative or positive feedback to the learning element.\n",
    "* Depending on the received feedback, the **Learning-Element** adapts elements of the Performing Element.\n",
    "* The **Explore** element suggests actions, which do not fully **exploit** the current available knowledge, but enables the agent to gather new **experience**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
